# 结构解析/小说特化

下面按你要的 4 件事来讲：**(1) CosyVoice 要不要像 XTTS 一样手工加 break**、**(2) CosyVoice vs XTTS 在中英文断句的本质差异**、**(3) “中文小说→CosyVoice 最优切分算法”**、**(4) 对话感知分段器 + 有声书级 pipeline/参数模板**，以及最后补充 **结构解析/小说特化**。

---

## 1) 中文小说给 CosyVoice：还要不要额外加 break？

结论：**仍然建议你“显式切分 + 在段尾保证有终止标点”，不要指望模型完全替你处理**。

原因分两层：

1. **CosyVoice(尤其 zero-shot)对“句末标点”更敏感**
   社区里有人报告：zero-shot 时如果 prompt/target 文本**不以标点结尾**会触发报错或异常行为（比如要求以 `. ? !` 等结尾）。([GitHub][1])

> 这说明：**“句子边界/终止符”在 CosyVoice 的前端/推理流程里是一个强约束**，至少在某些版本/路径下不是可有可无。

2. **CosyVoice2 确实更“端到端”，但不等于不需要切分**
   CosyVoice2 强调可以直接用 raw text 输入、甚至“Text Normalization 无需传统 frontend”。([FunAudioLLM][2])
   但“能读”≠“有声书级别的节奏/情绪/稳定性最好”。长段落不切分，常见问题是：
* 韵律变平、语速漂、情绪不连贯或过度连贯（该停不停）
* 生成稳定性下降（长上下文更容易出小错）
* 后处理（拼接、响度统一、错字回滚）更难做

**推荐做法（实用到能落地）：**

* **不需要 SSML 的 `<break>`**（CosyVoice 并不一定支持 SSML break 标签；很多项目是“分段生成后自己拼接静音”来实现 pause）
* 你要做的是：**“切成合适的可控片段 + 每段结尾补齐 `。！？…` 等终止标点 + 段间按类型插入静音”**

---

## 2) CosyVoice vs XTTS：中英文断句上的本质差异

### XTTS（Coqui XTTS v2）的“断句”更像 **工程限制驱动**

* XTTS 常见是**有字符/上下文长度限制**，因此默认把长文本拆成句子生成再拼接（官方文档就描述了“splits the text into sentences and generates audio for each sentence, then concatenates”，并且可以选择禁用拆句以换取更强一致性但更吃显存/更容易撞上下文限制）。([Coqui Docs][3])
* 所以 XTTS 的断句目标往往是：
  **“别超长 + 别爆显存/上下文 + 别卡住”**
  语气/情绪的“有声书级控制”更多得靠你在文本层面做结构化（引号、换行、旁白/对话分离）以及后处理。

### CosyVoice（尤其 CosyVoice2）的“断句”更像 **韵律边界与前端约束驱动**

* CosyVoice 的链路里（尤其早期/某些推理模式）**句末标点是硬信号**，甚至会导致 zero-shot 路径出错。([GitHub][1])
* CosyVoice2 虽然更端到端（raw text / TN 更强），但你为了“有声书”，切分不再只是“避免限制”，而是为了：
  **“把叙事结构映射到 prosody（停连、重音、语气）”**
* 另外 CosyVoice 体系里 TN 可用 ttsfrd（可选）或 wetext（默认）增强规范化。([Hugging Face][4])
  这会影响你对数字/符号/外文夹杂的处理策略：你可以少做一些 TN，但更要做 **结构切分**。

一句话总结差异：

* **XTTS：切分主要为“可生成”服务（长度/资源约束）**
* **CosyVoice：切分更多为“好听、稳定、可控”服务（韵律边界/终止符/结构映射）**

---

## 3) “中文小说 → CosyVoice 最优切分算法”（可直接照着实现）

目标：在不破坏语义/对话结构的前提下，把小说切成**可控长度**的片段，并最大化“自然停顿点”。

### 3.1 打分思路（可做 DP / 贪心都行）

给候选切分点一个 score，优先在高分处切：

**强切分点（高分）**

* 段落空行、章节标题后
* `。！？……` 结尾
* 对话结束引号 `”` 后紧跟叙述（如 `”她说。`）且句尾有标点

**弱切分点（中分）**

* `，；：` 之后（但尽量别在逗号切，除非超长）
* 英文句号/问号/感叹号

**强惩罚（不要切）**

* 引号 `“ ”` 内部切断且会把一句话切成两半（除非超长必须切）
* 数字/单位中间：`12.5%`、`3:45`、`2025-10-11`、`1,000` 等
* 人名/专有名词被切碎（可用简单规则：连续中文2~4字且后面跟“说/道/问/笑”等，尽量不断开）

### 3.2 建议的硬约束（经验值）

对 CosyVoice 做有声书，一般你会更舒服：

* **每段 60–140 个中文字符**（对话可更短：20–80）
* **最长不超过 180–220 字**（超了稳定性/韵律更容易崩）
* 每段末尾**强制补一个终止标点**：`。`（叙述）/`！`/`？`（对话情绪）
  （这条对 zero-shot 路径尤其重要）([GitHub][1])

### 3.3 最优切分（推荐实现：带回退的贪心）

1. 先按**章节/空行**切大块
2. 每块内按**强标点**再切
3. 对超长句：在 `，；：` 等弱边界做二次切
4. 还超：允许在引号内按 `，` 切，但要保证引号配对、且切后两段都补标点
5. 每段尾：若不是 `。！？…` 结尾 → 按类型补一个

---

## 4) 对话感知的中文分段器（给你一份“够用且易扩展”的实现）

下面这份是**规则派**（不依赖大模型），特点：

* 识别章节标题、旁白段落
* 识别中文引号对话 `“…”`（含同段多个对话）
* 对话段优先保持 speaker turn，不随便把一个 turn 切碎
* 自动长度控制 + 段尾补终止标点
* 产出带 `kind=narration/dialog/title` 的段，方便你后面做“不同说话风格/不同停顿/不同 speaker embedding”

```python
import re
from dataclasses import dataclass
from typing import List, Literal, Iterable

Kind = Literal["title", "narration", "dialog"]

@dataclass
class Segment:
    text: str
    kind: Kind

# ---- 基础清洗与工具 ----

TITLE_RE = re.compile(r"^\s*(第[一二三四五六七八九十百千万0-9]+[章节回卷部].{0,20}|楔子|序章|序|后记|番外.{0,10})\s*$")

END_PUNC_RE = re.compile(r"[。！？…]+$")   # 允许 …… 或 ……
HARD_SPLIT_RE = re.compile(r"([。！？…]+)(?!”)\s*")  # 句末强切（尽量不把 ” 后面的粘走）
WEAK_SPLIT_RE = re.compile(r"([；：，])\s*")

QUOTE_RE = re.compile(r"“([^”]+)”")  # 简化版：不处理跨段引号（结构解析里会讲怎么增强）

def normalize_text(s: str) -> str:
    s = s.replace("\u3000", " ")          # 全角空格
    s = re.sub(r"[ \t]+", " ", s)
    s = s.replace("……", "…")              # 统一省略号（可选）
    s = s.replace("——", "—")              # 统一破折号（可选）
    return s.strip()

def ensure_end_punc(s: str, kind: Kind) -> str:
    s = s.strip()
    if not s:
        return s
    if END_PUNC_RE.search(s):
        return s
    # 对话常用“。”也行；如果你想更“口语”，可根据是否包含疑问词来补 ？/！
    return s + ("。" if kind != "title" else "")

# ---- 核心：对话感知切分 ----

def split_by_hard_punc(s: str) -> List[str]:
    # 保留分隔符
    parts = []
    start = 0
    for m in HARD_SPLIT_RE.finditer(s):
        end = m.end()
        chunk = s[start:end].strip()
        if chunk:
            parts.append(chunk)
        start = end
    tail = s[start:].strip()
    if tail:
        parts.append(tail)
    return parts

def split_to_maxlen(s: str, max_len: int) -> List[str]:
    """把一个句子进一步切到 max_len 以内：优先弱标点，其次硬切。"""
    s = s.strip()
    if len(s) <= max_len:
        return [s]

    # 先按弱标点分
    tokens = []
    buf = ""
    i = 0
    while i < len(s):
        buf += s[i]
        if s[i] in "，；：":
            tokens.append(buf.strip())
            buf = ""
        i += 1
    if buf.strip():
        tokens.append(buf.strip())

    # 重新拼成不超过 max_len 的块
    out, cur = [], ""
    for t in tokens:
        if not cur:
            cur = t
        elif len(cur) + len(t) <= max_len:
            cur += t
        else:
            out.append(cur.strip())
            cur = t
    if cur.strip():
        out.append(cur.strip())

    # 如果还有超过 max_len 的，做硬切回退
    final = []
    for x in out:
        if len(x) <= max_len:
            final.append(x)
        else:
            # 极端长无标点：直接切片
            for j in range(0, len(x), max_len):
                final.append(x[j:j+max_len].strip())
    return [z for z in final if z]

def dialog_aware_segment(paragraph: str,
                         max_len: int = 160,
                         dialog_max_len: int = 90) -> List[Segment]:
    """
    输入一个“段落”（已按空行切过），输出 narration/dialog/title 的 Segment 列表。
    """
    p = normalize_text(paragraph)
    if not p:
        return []

    if TITLE_RE.match(p):
        return [Segment(text=p, kind="title")]

    segs: List[Segment] = []

    # 1) 把段落按引号对话拆成：旁白片段 + 对话片段 + 旁白片段...
    last = 0
    for m in QUOTE_RE.finditer(p):
        # 旁白
        nar = p[last:m.start()].strip()
        if nar:
            segs.append(Segment(nar, "narration"))
        # 对话
        dia = m.group(0).strip()  # 包含引号
        segs.append(Segment(dia, "dialog"))
        last = m.end()

    tail = p[last:].strip()
    if tail:
        segs.append(Segment(tail, "narration"))

    # 2) 对每个片段做强标点切分 + 长度控制
    out: List[Segment] = []
    for s in segs:
        if s.kind == "title":
            out.append(s)
            continue

        # 对话：尽量不切碎一个 turn（先按句末强标点切，超长再弱切）
        chunks = split_by_hard_punc(s.text)
        maxl = dialog_max_len if s.kind == "dialog" else max_len

        for c in chunks:
            # 超长再二次切
            for piece in split_to_maxlen(c, maxl):
                piece = ensure_end_punc(piece, s.kind)
                out.append(Segment(piece, s.kind))

    return out

def segment_novel(text: str,
                  max_len: int = 160,
                  dialog_max_len: int = 90) -> List[Segment]:
    # 按空行切段落
    paras = [x for x in re.split(r"\n\s*\n+", text) if x.strip()]
    all_segs: List[Segment] = []
    for para in paras:
        all_segs.extend(dialog_aware_segment(para, max_len=max_len, dialog_max_len=dialog_max_len))
    return all_segs
```

你后续可以非常容易扩展：

* 把 `QUOTE_RE` 升级到“跨段引号/嵌套引号/英文引号”的状态机
* 在 `ensure_end_punc` 里根据对话内容（含“吗/呢/？/！”）补不同终止符
* 输出时附带 `pause_ms_after`，用来控制段间停顿

---

## 5) 一套“有声书级别”的参数 & pipeline 模板（CosyVoice / XTTS 都能套）

> 我这里不强行写死某个 CosyVoice 版本的“温度/Top-p/Top-k API 名称”，因为不同仓库/推理封装暴露的参数不完全一致；但**流程和调参方向**是通用且最重要的。

### 5.1 Pipeline（强烈建议照这个分层）

**A. 文本层（决定 80% 的“像不像有声书”）**

1. 章节识别 → 输出 `title / narration / dialog`

2. 引号规范化（中文“”统一，修复缺失的右引号）

3. TN：数字、日期、时间、英文缩写、货币单位
   
   * CosyVoice2 主打 TN 更强、可不依赖传统前端。([Hugging Face][5])
   * CosyVoice 生态也允许可选 ttsfrd（否则用 wetext）。([Hugging Face][4])

4. **对话感知切分**（上面给的代码）

5. 段尾终止标点保证（对 zero-shot 很关键）([GitHub][1])

**B. 生成层（稳定性与一致性）**

1. speaker：
   
   * 同一角色固定 speaker embedding / prompt audio（别每句都换参考音频）

2. 生成策略：
   
   * **降低随机性**（更稳更少口误）
   * 超长句宁可再切短，也别靠“提高随机性”去赌

3. 失败回退：
   
   * 某段出错 → 自动再切半 → 重试
   * 仍出错 → 退回更保守的 TN/标点策略

**C. 音频后处理层（让它像“出版物”）**

1. 段间插入静音（而不是依赖模型 break 标签）
   
   * narration 段间：120–220ms
   * dialog turn 间：180–350ms
   * 场景切换/章节：500–900ms

2. 拼接：可选 5–20ms crossfade 防爆音

3. 响度统一：全书统一 LUFS（例如 -18 ~ -20 LUFS），峰值限制（-1dBFS）

4. 质检：
   
   * 检测异常长静音、削波、明显重读/卡顿
   * 关键句（对话高潮/人名首次出现）抽检

### 5.2 参数方向（“有声书级”优先级）

**优先级 1：稳定性 > 表演力**

* 有声书最怕：口误、吞字、重复、忽快忽慢
* 所以你要把“随机性”压低，把“切分”做精细

**优先级 2：对话的节奏**

* 对话段比旁白更短、更频繁停顿
* 同一说话人连续多句要“连读”，不同说话人要“明显分隔”

**优先级 3：跨语言与夹杂（中英混读）**

* CosyVoice2 支持多语与混读是卖点之一([FunAudioLLM][6])
* 你仍然要在文本上标清边界：例如英文缩写两侧加空格，避免粘连成怪词

---

## 6) 结构解析 / 小说特化：为什么它会显著提升效果？

“结构解析”本质是：**把小说从“纯文本”提升为“可控脚本”**。

你至少要抽 4 类结构：

1. **章节/场景**（Chapter/Scene）
* 决定“大停顿”、可能换背景音/换说话风格
2. **旁白 vs 对话**
* 决定语速、停顿密度、情绪幅度
* 对话往往需要更强的语气词处理（“嗯”“啊”“欸”）和更短的切分
3. **说话人线索（Speaker hint）**
* “他/她说”“老王骂道”“小李低声问”
* 哪怕你不做多角色 TTS，也可以用它来决定：这一句要不要更“轻/重/快/慢”
4. **标点与语气强化**
* 小说里大量“……” “—” “？” “！！”是“表演指令”
* 如果你把它们在切分阶段弄丢了，音频会立刻变“朗读腔”或“播报腔”

---

如果你愿意把你的一小段样例（含：一段旁白 + 一段对话 + 一段中英夹杂/数字日期）贴出来，我可以直接按上面算法给你**切分结果示例**（每段多长、段间停顿多少、哪里补标点/怎么修引号），并把分段器规则再针对你的文本风格（网文/出版小说/轻小说）做一次定制。

[1]: https://github.com/FunAudioLLM/CosyVoice/issues/57?utm_source=chatgpt.com "Error happened during zero shot TTS for text that does not ..."
[2]: https://funaudiollm.github.io/pdf/CosyVoice_2.pdf?utm_source=chatgpt.com "CosyVoice 2: Scalable Streaming Speech Synthesis with ..."
[3]: https://docs.coqui.ai/en/dev/models/xtts.html?utm_source=chatgpt.com "Training - TTS 0.22.0 documentation"
[4]: https://huggingface.co/FunAudioLLM/CosyVoice-ttsfrd?utm_source=chatgpt.com "FunAudioLLM/CosyVoice-ttsfrd"
[5]: https://huggingface.co/FunAudioLLM/CosyVoice2-0.5B?utm_source=chatgpt.com "FunAudioLLM/CosyVoice2-0.5B"
[6]: https://funaudiollm.github.io/cosyvoice2/?utm_source=chatgpt.com "CosyVoice2.0"

# 如何解析?

这个问题问得**非常专业，也非常现实**。
先给你一句**不拐弯的结论**，然后我再分层讲清楚。

---

## 结论先行（很重要）

> **❌ 目前「没有一个成熟、通用、专门为 *中文小说结构解析* 设计的一站式开源库」**
> 
> **✅ 但：可以用「NLP 组件 + 规则系统」拼出一个 *工业可用* 的小说结构解析器**
> 
> 而且**几乎所有真正能落地的有声书 / TTS 项目，都是这么干的**。

也就是说：
**你找不到“ChineseNovelParser.py”这种神器，但你能搭出一套比 90% 项目都强的方案。**

---

## 一、为什么“小说结构解析”很难有通用库？

这是根本原因，理解了你就不会再纠结“为什么没人做”。

### 1️⃣ 小说 ≠ NLP 传统任务

NLP 常见任务是：

* 分词
* 句法分析
* NER
* 情感分析

而**小说结构解析**关心的是：

| 小说解析关心   | NLP 常规模型关心 |
| -------- | ---------- |
| 对话 vs 旁白 | 实体、句法      |
| 说话轮次     | 词性         |
| 情绪/语气    | 情感极性       |
| 节奏/停顿    | 语义相似       |
| “好不好听”   | 准不准确       |

👉 **目标函数完全不同**
所以很少有人为“有声书/TTS”专门训练模型。

---

### 2️⃣ 小说文本风格极度不统一

* 网文 / 出版小说 / 轻小说 / 古文 / 翻译腔

* 引号：
  
  * “……”
  * 「……」
  * 有的甚至不用引号

* 说话提示：
  
  * 他说
  * 他冷笑
  * 他低声骂道
  * 完全省略

👉 **这类问题极其依赖规则 + 经验，而不是纯模型**

---

## 二、现状盘点：有哪些「接近但不完全对口」的开源工具？

下面我按**“能用来拼方案”**的角度给你梳理，而不是“名气最大”。

---

## ① 中文分句 / 断句（基础组件）

### 可用价值：⭐⭐⭐⭐☆

#### 常见工具

* **pyltp / LTP**
* **HanLP**
* **pkuseg**
* **jieba（仅勉强）**

它们能做的：

* 基于标点、语法的分句
* 基础句边界识别

不能做的：

* ❌ 不理解“小说对话结构”
* ❌ 不识别说话轮次
* ❌ 不知道“这是旁白还是对白”

👉 **只适合作为“最底层工具”，不能直接用来喂 TTS**

---

## ② 引号 / 对话识别（半结构化）

### 可用价值：⭐⭐⭐⭐☆

这是**最有价值的一层**，但通常是“散落在项目里”，而不是一个完整库。

#### 常见做法

* 正则 + 状态机：
  
  * 识别 `“ … ”`
  * 跨段引号补全

* 对话块提取：
  
  * 一个段落中多个对话轮次

#### 特点

* 非常适合小说
* 工程可控
* 可解释

👉 **90% 有声书项目核心就是这一层**

---

## ③ 说话人 / 话语动词识别（He said problem）

### 可用价值：⭐⭐⭐☆☆

#### 常用技术

* 正则 + 词表：
  
  * 说 / 道 / 问 / 喊 / 冷笑 / 低声 / 喃喃

* 有时会用：
  
  * 依存句法分析（HanLP / LTP）

#### 局限

* 无法 100% 确定 speaker
* 但 **对 TTS 来说，80% 已经够用了**

👉 **TTS 不需要“谁在说话”，只需要“这是对话”**

---

## ④ 情绪 / 语气（可选，高级）

### 可用价值：⭐⭐☆☆☆

* 情感分析模型（正/负/中性）
* 情绪词表（叹气、怒吼、低声）

**但注意**：

* 这一步不是必须
* 很容易过拟合
* 多数项目只做“弱提示”

---

## 三、有没有「接近小说解析」的开源项目？（实话）

### ✅ 有“局部解决方案”

### ❌ 没有“开箱即用小说结构解析库”

比较接近的方向有三类：

---

### 1️⃣ NLP 教学 / 学术项目（不适合直接用）

* 小说对话识别研究
* 文学文本分析

问题：

* 偏论文
* 不稳定
* 不为工程服务

---

### 2️⃣ 语音 / TTS 项目里的“隐性实现”（最有价值）

在一些 TTS / audiobook 项目里：

* **小说解析代码是“内嵌在 pipeline 里”**

* 不是一个独立库

* 通常是：
  
  * 正则
  * 状态机
  * 一堆 if-else 😅

👉 **你已经走在这条路上了**

---

### 3️⃣ 商业产品（不开源）

* 听书 App
* AI 播音 / AI 配音平台

这些**一定有成熟的小说解析模块**，但：

* 不开源
* 极度定制
* 规则堆出来的

---

## 四、那“专业项目”通常怎么做？（核心真相）

> **小说结构解析 = 规则系统 + NLP 辅助，而不是反过来**

### 工业级常见架构：

```
文本输入
  ↓
基础清洗（空行/标点/引号）
  ↓
章节识别（规则）
  ↓
段落识别（空行）
  ↓
对话块识别（引号状态机）
  ↓
说话提示识别（词表+正则）
  ↓
分段（长度 + 角色/旁白策略）
  ↓
TTS
```

**注意**：

> 规则是主干
> NLP 是“增强模块”，不是大脑

---

## 五、给你一个非常重要的建议（基于你的背景）

你已经：

* 做 TTS
* 用 CosyVoice / XTTS
* 做有声书级 pipeline

👉 **你现在最优解不是“找库”，而是“把规则系统工程化”**

### 推荐你做这三件事（比找库有用 10 倍）：

1. **把小说解析写成独立模块**
   
   * `NovelParser`
   * 输出结构化 JSON（chapter / narration / dialog / length / pause）

2. **把规则参数化**
   
   * 引号风格
   * 最大段长
   * 对话优先级
   * 停顿策略

3. **保留人工 override 能力**
   
   * 因为 5% 的“名场面”值得人工调

---

## 六、如果你愿意，我可以继续帮你到「产品级」

接下来我可以直接帮你做其中任一件（都很实用）：

* ✅ 把刚才的分段器升级成 **完整 NovelParser 类**
* ✅ 给你一个 **JSON Schema（可存可回放）**
* ✅ 设计 **规则 DSL（比写 if-else 更干净）**
* ✅ 做 **中英混合小说的结构解析策略**
* ✅ 对比「规则 vs LLM 辅助解析」什么时候值得上大模型

你更想往 **工程落地** 还是 **极致音质/表现力** 再走一步？
